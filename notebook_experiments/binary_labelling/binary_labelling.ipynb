{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "binary_labelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXCz1SKzUgF2"
      },
      "source": [
        "# GBV Article Binary Classification\n",
        "\n",
        "**Acknowledgement**: The LSTM code in this notebook was adapted from the following two tutorials\n",
        "1. https://www.kaggle.com/swarnabha/pytorch-text-classification-torchtext-lstm#Sentence-Classification \n",
        "2. https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olf6pfG5lFab",
        "outputId": "73046ba1-dbaf-4a0e-b4b3-771670bee55f"
      },
      "source": [
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting es_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (56.1.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-cp37-none-any.whl size=16172936 sha256=58f2a42e26cf3c4fce16a17682c919d7ca8131387ca42e04007e2d895f070f02\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7vljsf1y/wheels/05/4f/66/9d0c806f86de08e8645d67996798c49e1512f9c3a250d74242\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNkEL3LbILn1"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy import data\n",
        "import torchtext\n",
        "from torchtext.vocab import Vectors\n",
        "import spacy "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKVK4mL7auL6",
        "outputId": "83ba54b7-8731-4166-b89a-022959b374ac"
      },
      "source": [
        "!pip install altair\n",
        "import altair as alt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: altair in /usr/local/lib/python3.7/dist-packages (4.1.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from altair) (1.19.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair) (0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair) (2.11.3)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.7/dist-packages (from altair) (1.1.5)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair) (0.11.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18->altair) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18->altair) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVfWkFpHmg-6"
      },
      "source": [
        "def altair_theme():\n",
        "    '''\n",
        "    Helper function to set up the theme for altair (to create plots)\n",
        "    '''\n",
        "    font = \"Playfair Display, serif\"\n",
        "    labelFont = \"Raleway, sans-serif\"\n",
        "    fontColor = '#3c3f42'\n",
        "    axisColor = \"#9E9EA3\"\n",
        "    gridColor = \"#D1D4D6\"  \n",
        "    main_palette = [\"#06063c\",\"#c5741d\",\"#902727\",\"#265886\",\"#dab312\",\"#523378\",\"#3e8c7e\",\"#5f8540\"]\n",
        "    return {\n",
        "        \"config\": {\n",
        "            \"title\": {\n",
        "                \"fontSize\": 20,\n",
        "                \"font\": font,\n",
        "                \"anchor\": \"start\", \n",
        "                \"color\": fontColor,\n",
        "                \"fontWeight\": 600,\n",
        "                \"offset\": 20,\n",
        "            },\n",
        "            \"axisX\": {\n",
        "                \"domain\": True,\n",
        "                \"domainColor\": axisColor,\n",
        "                \"domainWidth\": 1,\n",
        "                \"grid\": False,\n",
        "                \"labelFont\": labelFont,\n",
        "                \"labelFontSize\": 12,\n",
        "                \"labelPadding\": 10,\n",
        "                \"labelColor\": fontColor,\n",
        "                \"labelFontWeight\": 100,                \n",
        "                \"tickColor\": axisColor,\n",
        "                \"tickSize\": 5, \n",
        "                \"titleFont\": font,\n",
        "                \"titleFontSize\": 16,\n",
        "                \"titleFontWeight\": 100,\n",
        "                \"titlePadding\": 10, \n",
        "                \"titleColor\": fontColor,\n",
        "            },\n",
        "            \"axisY\": {\n",
        "                \"domain\": False,\n",
        "                \"grid\": True,\n",
        "                \"gridColor\": gridColor,\n",
        "                \"gridWidth\": 1,\n",
        "                \"labelFont\": labelFont,\n",
        "                \"labelFontSize\": 11,\n",
        "                \"labelPadding\": 10,\n",
        "                \"labelColor\": fontColor,\n",
        "                \"labelFontWeight\": 100,                \n",
        "                \"ticks\": False, \n",
        "                \"titleFont\": font,\n",
        "                \"titleFontSize\": 14,\n",
        "                \"titleFontWeight\": 600,\n",
        "                \"titleColor\": fontColor,\n",
        "                \"titleY\": -15, \n",
        "                \"titleX\": -10, \n",
        "                \"titlePadding\": 10, \n",
        "                \"titleAngle\": 0, \n",
        "            },\n",
        "            \"legend\": {\n",
        "                \"labelFont\": labelFont,\n",
        "                \"labelFontSize\": 12,\n",
        "                \"labelColor\": fontColor,\n",
        "                \"labelFontWeight\": 100,                \n",
        "                \"symbolType\": \"square\", \n",
        "                \"titleFont\": labelFont,\n",
        "                \"titleFontSize\": 12,\n",
        "                \"title\": \"\", \n",
        "                # \"orient\": \"top-right\", \n",
        "            },\n",
        "            \"view\": {\n",
        "                \"strokeWidth\": 0\n",
        "\n",
        "            }\n",
        "        }\n",
        "    }"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gL9oumPmwN2",
        "outputId": "f8952647-e4a9-46ef-b3ed-661ed2ec0dc7"
      },
      "source": [
        "alt.themes.register(\"altair_theme\", altair_theme)\n",
        "alt.themes.enable(\"altair_theme\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThemeRegistry.enable('altair_theme')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66hv8hn-UHkQ"
      },
      "source": [
        "## 1. Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQEkAveeHUE1",
        "outputId": "b9147b25-be85-45ec-aa0a-42c21b6cf651"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "if USE_CUDA:\n",
        "    DEVICE = torch.device('cuda')\n",
        "    print(\"Using cuda.\")\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "    print(\"Using cpu.\")\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "PATH = \"gdrive/MyDrive/\"\n",
        "\n",
        "random.seed(30255)\n",
        "np.random.seed(30255)\n",
        "torch.manual_seed(30255)\n",
        "if USE_CUDA:\n",
        "    torch.cuda.manual_seed(30255)\n",
        "\n",
        "# Change the following to false when training on the full set\n",
        "#DEVELOPING = True    \n",
        "DEVELOPING = False\n",
        "\n",
        "country_paths = {\"MEXICO\": [\"mexico_el_universal_scraped_lab\", \"mexico_heraldo_scraped_labelled\", \"mexico_la_jornada_scraped_label\"],\n",
        "                 \"PAKISTAN\": [\"pakistan_dawn_labelled300\",\"pakistan_news_labelled300\", \"pakistan_nation_labelled300\"],\n",
        "                 \"UK\": [\"uk_sun_scraped_cleaned_labelled\", \"uk_times_scraped_cleaned_labell\", \"uk_guardian_scraped_cleaned_lab\"]}\n",
        "\n",
        "# specify the country to build the model for\n",
        "COUNTRY = \"PAKISTAN\"\n",
        "\n",
        "if DEVELOPING:\n",
        "    print(\"small test dataset\")\n",
        "    df = pd.read_csv(PATH + 'labelling_data - uk_guardian_scraped_cleaned_labelled300.csv')[['webTitle', 'GBV']]\n",
        "    df.columns = ['text', 'target']\n",
        "else:\n",
        "    data_xlsx = pd.ExcelFile(PATH + 'labelling_data.xlsx')\n",
        "    list_df = []\n",
        "    for sheet_name in country_paths[COUNTRY]:\n",
        "        columns = ['webTitle', 'GBV'] if sheet_name == \"uk_guardian_scraped_cleaned_lab\" else [\"title\", \"GBV\"]\n",
        "        sdf = pd.read_excel(data_xlsx, sheet_name=sheet_name)[columns]\n",
        "        sdf.columns = ['text', 'target']\n",
        "        list_df.append(sdf)\n",
        "    df = pd.concat(list_df)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu.\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2kw4wmVeh0nW",
        "outputId": "5de03bd5-033d-4af0-cdfa-95531510d84d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Government College University VC in Lahore ord...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16 days of activism drive launched against gen...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Another Zainab': 2-year-old girl assaulted, to...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kasur policeman arrested for allegedly killing...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‚ÄòHonour‚Äô in shame</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  Government College University VC in Lahore ord...     1.0\n",
              "1  16 days of activism drive launched against gen...     1.0\n",
              "2  Another Zainab': 2-year-old girl assaulted, to...     1.0\n",
              "3  Kasur policeman arrested for allegedly killing...     1.0\n",
              "4                              ‚ÄòHonour‚Äô in shame     1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6VfSvFEUPsl"
      },
      "source": [
        "## 2. Set up data\n",
        "\n",
        "### 2.1 Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePjI6oAlILn7"
      },
      "source": [
        "def normalise_text(text):\n",
        "    ''' \n",
        "    Normalise and clean text (remove html tags, set to lower case etc)\n",
        "    inputs:\n",
        "        text: str, the text to be cleaned\n",
        "    returns: str, the cleaned and normalised text\n",
        "    '''\n",
        "    text = text.str.lower() # lowercase\n",
        "    text = text.str.replace(r\"\\#\",\"\") # replaces hashtags\n",
        "    text = text.str.replace(r\"http\\S+\",\"URL\")  # remove URL addresses\n",
        "    text = text.str.replace(r\"@\",\"\")\n",
        "    text = text.str.replace(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \") # strip out punctuation\n",
        "    text = text.str.replace(\"\\s{2,}\", \" \")\n",
        "    text = text.apply(lambda x: re.sub('<[^<]+?>', '', x)) # remove html tags\n",
        "    return text"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDHFVHM5ILn8"
      },
      "source": [
        "df.dropna(inplace=True)\n",
        "\n",
        "df['text'] = normalise_text(df['text'])    "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id4g7V02WBck"
      },
      "source": [
        "### 2.2 Split df into train, test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-GzUEHvILn9"
      },
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.15)\n",
        "train_df, vali_df = train_test_split(train_df, test_size=0.2)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2cPi3MDb2K4",
        "outputId": "8e17bed1-c3ef-4f2f-c6e7-c5151b1b8959"
      },
      "source": [
        "print(\"training dataset shape: \", train_df.shape)\n",
        "print(\"validation dataset shape: \", vali_df.shape)\n",
        "print(\"test dataset shape: \", test_df.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training dataset shape:  (466, 2)\n",
            "validation dataset shape:  (117, 2)\n",
            "test dataset shape:  (103, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f3P1abDWZiJ"
      },
      "source": [
        "### 2.3 Create text and data iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5s0HlNYILn-"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3BMEFDIILn_"
      },
      "source": [
        "if COUNTRY == 'MEXICO':\n",
        "    tokenizer_language = 'es_core_news_sm'\n",
        "else:\n",
        "    tokenizer_language = 'en_core_web_sm'\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', tokenizer_language=tokenizer_language, include_lengths=True, batch_first=True)\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MWrTarsILn_"
      },
      "source": [
        "# source : https://gist.github.com/lextoumbourou/8f90313cbc3598ffbabeeaa1741a11c8\n",
        "# to use DataFrame as a Data source\n",
        "\n",
        "class DataFrameDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
        "        examples = []\n",
        "        for i, row in df.iterrows():\n",
        "            label = row.target if not is_test else None\n",
        "            text = row.text\n",
        "            examples.append(data.Example.fromlist([text, label], fields))\n",
        "\n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return len(ex.text)\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
        "        train_data, val_data, test_data = (None, None, None)\n",
        "        data_field = fields\n",
        "\n",
        "        if train_df is not None:\n",
        "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
        "        if val_df is not None:\n",
        "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
        "        if test_df is not None:\n",
        "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
        "\n",
        "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW7N_QkfILoA"
      },
      "source": [
        "fields = [('text',TEXT), ('label',LABEL)]\n",
        "\n",
        "train_ds, val_ds = DataFrameDataset.splits(fields, train_df=train_df, val_df=vali_df)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArVHgyuZILoA",
        "outputId": "5757bd52-6589-4dbf-b1dc-6bffbc8f37ad"
      },
      "source": [
        "print(\"Example of data: \", vars(train_ds[15]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of data:  {'text': ['boy', 'dies', 'six', 'others', 'burnt', 'in', 'gas', 'explosion'], 'label': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k4rKK7qILoB"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "if COUNTRY == 'MEXICO':\n",
        "    # trained_vectors = Vectors('cc.es.300.bin')\n",
        "    TEXT.build_vocab(train_ds, \n",
        "                    max_size = MAX_VOCAB_SIZE)\n",
        "else:\n",
        "    TEXT.build_vocab(train_ds, \n",
        "                    max_size = MAX_VOCAB_SIZE, \n",
        "                    vectors = 'glove.6B.200d',\n",
        "                    unk_init = torch.Tensor.zero_)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmamQyeVILoB"
      },
      "source": [
        "LABEL.build_vocab(train_ds)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo1-D3zjILoB"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_ds, val_ds), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGT0OHJfXS5W"
      },
      "source": [
        "## 3. Set up model\n",
        "\n",
        "### 3.1 Model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5KLWIUXILoC"
      },
      "source": [
        "num_epochs = 25\n",
        "learning_rate = 0.001\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.2\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBQVw95BXYes"
      },
      "source": [
        "### 3.2 Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v12MI5_sILoC"
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):              \n",
        "        embedded = self.embedding(text)\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        dense_outputs = self.fc1(hidden)\n",
        "        outputs = self.dropout(self.fc2(dense_outputs))            \n",
        "        return outputs"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irlk3cR2ILoC"
      },
      "source": [
        "model = LSTM_net(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4GHF2yCYKck"
      },
      "source": [
        "### 3.3 Initialise embedding layer with GloVe embeddings (for UK and Pakistan models only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3TiHJnUILoC"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOf9jTLGILoD",
        "outputId": "a09734a2-d81c-4c6e-ecf1-cf1102e131d0"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.1027,  0.3041, -0.1358,  ...,  0.3695,  0.1904, -0.1227],\n",
              "        ...,\n",
              "        [-0.2565,  0.7228, -0.5316,  ..., -0.4012, -0.8587, -0.0942],\n",
              "        [ 0.0945, -0.1654, -0.8128,  ..., -0.3747, -0.0331,  0.6317],\n",
              "        [-0.0660, -0.0530, -0.3336,  ..., -0.6483, -0.4552,  0.1592]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJPkRiF3ILoD"
      },
      "source": [
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hPxINiYILoD"
      },
      "source": [
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtulwwMbYitI"
      },
      "source": [
        "## 4. Train model\n",
        "\n",
        "### 4.1 Define model training and evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBWdSmMtILoE"
      },
      "source": [
        "def binary_accuracy(preds, targets):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, for example if the model predicts 8/10 right, this returns 0.8\n",
        "    inputs:\n",
        "        preds: list of floats, the predictions for the batch from the model\n",
        "        targets: list of floats, the targets (pre-labels) for the batch\n",
        "    returns: float, the proportion of correct labels from the model\n",
        "    \"\"\"\n",
        "    # get binary predictions:\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == targets).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umC4l1QFILoE"
      },
      "source": [
        "def train_an_epoch(model, iterator):\n",
        "    '''\n",
        "    Trains the model for one epoc\n",
        "    inputs: \n",
        "        model: the instance of the model\n",
        "        iterator: the train data iterator\n",
        "    returns:\n",
        "        training loss, float\n",
        "        training accuracy, float\n",
        "    '''\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        text, text_lengths = batch.text\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF0xU-unILoE"
      },
      "source": [
        "def evaluate(model, iterator):\n",
        "    '''\n",
        "    Evaluate the model on the validation dataset\n",
        "    inputs:\n",
        "        model: the instance of the LSTM model\n",
        "        iterator: the validation data iterator\n",
        "    returns: validation accuracy, float\n",
        "    '''\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_acc / len(iterator)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kHrcYgraawn"
      },
      "source": [
        "### 4.2. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90TzzwIGILoF",
        "outputId": "08055fbc-7999-4d52-f976-e70d577de6bd"
      },
      "source": [
        "loss=[]\n",
        "acc=[]\n",
        "val_accs=[]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    train_loss, train_acc = train_an_epoch(model, train_iterator)\n",
        "    valid_acc = evaluate(model, valid_iterator)\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_accs.append(valid_acc)\n",
        "\n",
        "    if valid_acc >= max(val_accs):\n",
        "        torch.save(model.state_dict(), PATH + COUNTRY + 'saved_weights.pt')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.675 | Train Acc: 60.34%\n",
            "\t Val. Acc: 65.81%\n",
            "\tTrain Loss: 0.637 | Train Acc: 66.94%\n",
            "\t Val. Acc: 65.81%\n",
            "\tTrain Loss: 0.586 | Train Acc: 68.00%\n",
            "\t Val. Acc: 66.67%\n",
            "\tTrain Loss: 0.505 | Train Acc: 71.93%\n",
            "\t Val. Acc: 82.05%\n",
            "\tTrain Loss: 0.524 | Train Acc: 76.84%\n",
            "\t Val. Acc: 83.76%\n",
            "\tTrain Loss: 0.429 | Train Acc: 82.45%\n",
            "\t Val. Acc: 86.32%\n",
            "\tTrain Loss: 0.391 | Train Acc: 83.71%\n",
            "\t Val. Acc: 84.62%\n",
            "\tTrain Loss: 0.366 | Train Acc: 84.60%\n",
            "\t Val. Acc: 84.62%\n",
            "\tTrain Loss: 0.295 | Train Acc: 87.05%\n",
            "\t Val. Acc: 85.47%\n",
            "\tTrain Loss: 0.286 | Train Acc: 90.03%\n",
            "\t Val. Acc: 83.76%\n",
            "\tTrain Loss: 0.249 | Train Acc: 88.72%\n",
            "\t Val. Acc: 84.62%\n",
            "\tTrain Loss: 0.215 | Train Acc: 88.64%\n",
            "\t Val. Acc: 84.62%\n",
            "\tTrain Loss: 0.163 | Train Acc: 89.83%\n",
            "\t Val. Acc: 85.47%\n",
            "\tTrain Loss: 0.095 | Train Acc: 91.87%\n",
            "\t Val. Acc: 84.62%\n",
            "\tTrain Loss: 0.118 | Train Acc: 92.98%\n",
            "\t Val. Acc: 84.62%\n",
            "\tTrain Loss: -0.051 | Train Acc: 93.29%\n",
            "\t Val. Acc: 83.76%\n",
            "\tTrain Loss: -0.010 | Train Acc: 90.37%\n",
            "\t Val. Acc: 82.05%\n",
            "\tTrain Loss: 0.134 | Train Acc: 91.79%\n",
            "\t Val. Acc: 82.91%\n",
            "\tTrain Loss: 0.052 | Train Acc: 91.09%\n",
            "\t Val. Acc: 83.76%\n",
            "\tTrain Loss: 0.178 | Train Acc: 92.70%\n",
            "\t Val. Acc: 80.34%\n",
            "\tTrain Loss: -0.131 | Train Acc: 92.20%\n",
            "\t Val. Acc: 80.34%\n",
            "\tTrain Loss: -0.248 | Train Acc: 91.53%\n",
            "\t Val. Acc: 80.34%\n",
            "\tTrain Loss: -0.607 | Train Acc: 91.42%\n",
            "\t Val. Acc: 82.05%\n",
            "\tTrain Loss: -0.268 | Train Acc: 93.70%\n",
            "\t Val. Acc: 82.91%\n",
            "\tTrain Loss: -1.154 | Train Acc: 93.18%\n",
            "\t Val. Acc: 78.63%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "GOwwn2fEa2o3",
        "outputId": "5e84f88c-4972-4022-c2dd-41c70c74d027"
      },
      "source": [
        "plot_df = pd.DataFrame({'Validation Accuracy': val_accs, 'EPOC': range(1, num_epochs+1)})\n",
        "\n",
        "alt.Chart(plot_df).mark_line().encode(\n",
        "    x='EPOC:Q',\n",
        "    y=alt.Y('Validation Accuracy', scale=alt.Scale(domain=(0, 1)))\n",
        ").properties(width=250, height=350)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-495c1f5bdd2842cdaf6fe816855a94bd\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-495c1f5bdd2842cdaf6fe816855a94bd\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-495c1f5bdd2842cdaf6fe816855a94bd\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"title\": {\"fontSize\": 20, \"font\": \"Playfair Display, serif\", \"anchor\": \"start\", \"color\": \"#3c3f42\", \"fontWeight\": 600, \"offset\": 20}, \"axisX\": {\"domain\": true, \"domainColor\": \"#9E9EA3\", \"domainWidth\": 1, \"grid\": false, \"labelFont\": \"Raleway, sans-serif\", \"labelFontSize\": 12, \"labelPadding\": 10, \"labelColor\": \"#3c3f42\", \"labelFontWeight\": 100, \"tickColor\": \"#9E9EA3\", \"tickSize\": 5, \"titleFont\": \"Playfair Display, serif\", \"titleFontSize\": 16, \"titleFontWeight\": 100, \"titlePadding\": 10, \"titleColor\": \"#3c3f42\"}, \"axisY\": {\"domain\": false, \"grid\": true, \"gridColor\": \"#D1D4D6\", \"gridWidth\": 1, \"labelFont\": \"Raleway, sans-serif\", \"labelFontSize\": 11, \"labelPadding\": 10, \"labelColor\": \"#3c3f42\", \"labelFontWeight\": 100, \"ticks\": false, \"titleFont\": \"Playfair Display, serif\", \"titleFontSize\": 14, \"titleFontWeight\": 600, \"titleColor\": \"#3c3f42\", \"titleY\": -15, \"titleX\": -10, \"titlePadding\": 10, \"titleAngle\": 0}, \"legend\": {\"labelFont\": \"Raleway, sans-serif\", \"labelFontSize\": 12, \"labelColor\": \"#3c3f42\", \"labelFontWeight\": 100, \"symbolType\": \"square\", \"titleFont\": \"Raleway, sans-serif\", \"titleFontSize\": 12, \"title\": \"\"}, \"view\": {\"strokeWidth\": 0}}, \"data\": {\"name\": \"data-01d97e34e8a28a6bb14125d84fe82197\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"EPOC\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Validation Accuracy\", \"scale\": {\"domain\": [0, 1]}}}, \"height\": 350, \"width\": 250, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-01d97e34e8a28a6bb14125d84fe82197\": [{\"Validation Accuracy\": 0.6581196784973145, \"EPOC\": 1}, {\"Validation Accuracy\": 0.6581196784973145, \"EPOC\": 2}, {\"Validation Accuracy\": 0.6666666865348816, \"EPOC\": 3}, {\"Validation Accuracy\": 0.8205128312110901, \"EPOC\": 4}, {\"Validation Accuracy\": 0.8376068472862244, \"EPOC\": 5}, {\"Validation Accuracy\": 0.8632478713989258, \"EPOC\": 6}, {\"Validation Accuracy\": 0.8461538553237915, \"EPOC\": 7}, {\"Validation Accuracy\": 0.8461538553237915, \"EPOC\": 8}, {\"Validation Accuracy\": 0.8547008633613586, \"EPOC\": 9}, {\"Validation Accuracy\": 0.8376068472862244, \"EPOC\": 10}, {\"Validation Accuracy\": 0.8461538553237915, \"EPOC\": 11}, {\"Validation Accuracy\": 0.8461538553237915, \"EPOC\": 12}, {\"Validation Accuracy\": 0.8547008633613586, \"EPOC\": 13}, {\"Validation Accuracy\": 0.8461538553237915, \"EPOC\": 14}, {\"Validation Accuracy\": 0.8461538553237915, \"EPOC\": 15}, {\"Validation Accuracy\": 0.8376068472862244, \"EPOC\": 16}, {\"Validation Accuracy\": 0.8205128312110901, \"EPOC\": 17}, {\"Validation Accuracy\": 0.8290598392486572, \"EPOC\": 18}, {\"Validation Accuracy\": 0.8376068472862244, \"EPOC\": 19}, {\"Validation Accuracy\": 0.8034188151359558, \"EPOC\": 20}, {\"Validation Accuracy\": 0.8034188151359558, \"EPOC\": 21}, {\"Validation Accuracy\": 0.8034188151359558, \"EPOC\": 22}, {\"Validation Accuracy\": 0.8205128312110901, \"EPOC\": 23}, {\"Validation Accuracy\": 0.8290598392486572, \"EPOC\": 24}, {\"Validation Accuracy\": 0.7863247990608215, \"EPOC\": 25}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHpIXvo5f2MU"
      },
      "source": [
        "## 5. Evaluate the best model on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NakhWRWmILoG"
      },
      "source": [
        "model_saved ='saved_weights.pt'\n",
        "model.load_state_dict(torch.load(PATH + COUNTRY + 'saved_weights.pt'));\n",
        "model.eval();\n",
        "\n",
        "if COUNTRY == 'MEXICO':\n",
        "    nlp = spacy.load(\"es_core_news_sm\")\n",
        "else:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def predict(model, sentence):\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]        \n",
        "    length = [len(indexed)]                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)             \n",
        "    tensor = tensor.unsqueeze(1).T                            \n",
        "    length_tensor = torch.LongTensor(length) \n",
        "    prediction = model(tensor, length_tensor)\n",
        "    binary_pred = torch.round(torch.sigmoid(prediction)).item()\n",
        "    return abs(binary_pred-1)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFTqhP6sILoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343cd668-242a-40a1-ccf6-f5b62afece32"
      },
      "source": [
        "num_right = 0\n",
        "true_positives = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "for i, t in test_df.iterrows():\n",
        "    pred = predict(model, t['text'])\n",
        "    if pred == t['target']:\n",
        "        num_right += 1\n",
        "    if (pred == 1) and (t['target'] == 1):  \n",
        "        true_positives += 1\n",
        "    if (pred == 1) and (t['target'] == 0):\n",
        "        false_positives += 1\n",
        "    if (pred == 0) and (t['target'] == 1):\n",
        "        false_negatives += 1\n",
        "\n",
        "f1_score = true_positives / (true_positives + 0.5*(false_positives + false_negatives))\n",
        "\n",
        "print(\"{} best model: \\n percent of test set labelled correctly: {} \\n F1 score: {}\".format(COUNTRY, (num_right / test_df.shape[0])*100, f1_score))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PAKISTAN best model: \n",
            " percent of test set labelled correctly: 82.52427184466019 \n",
            " F1 score: 0.875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}